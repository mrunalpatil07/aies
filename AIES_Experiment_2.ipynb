{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrunalpatil07/aies/blob/main/AIES_Experiment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name:-Mrunal Patil                                                                  \n",
        "Class:- B.Tech B DIV                                                                       \n",
        "PRN NO. 22SC114501069                                                                  \n",
        "Title:- Impact of Data Quality on AI Fairness."
      ],
      "metadata": {
        "id": "bDdaouLeDNEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install fairlearn if not already installed\n",
        "# pip install fairlearn\n",
        "!pip install fairlearn\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from fairlearn.metrics import (\n",
        "    MetricFrame,\n",
        "    true_positive_rate,\n",
        "    false_positive_rate,\n",
        "    false_negative_rate,\n",
        "    selection_rate\n",
        ")\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/Student_Performance_on_an_Entrance_Examination.csv')\n",
        "\n",
        "# 🎯 Binary target: 1 if Performance is 'Excellent', else 0\n",
        "df['target'] = (df['Performance'] == 'Excellent').astype(int)\n",
        "\n",
        "# ⚖️ Sensitive feature\n",
        "sensitive_feature = 'Gender'\n",
        "\n",
        "# Drop rows with missing values in critical columns\n",
        "df = df.dropna(subset=['target', sensitive_feature])\n",
        "\n",
        "# 🔁 Drop columns not used\n",
        "drop_cols = ['Performance']  # Original performance column now replaced with binary 'target'\n",
        "df = df.drop(columns=drop_cols)\n",
        "\n",
        "# 🧠 Define categorical features to encode (excluding target and sensitive)\n",
        "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "categorical_cols = [col for col in categorical_cols if col != sensitive_feature]\n",
        "\n",
        "# One-hot encode\n",
        "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# ✨ Define X, y, and sensitive attribute\n",
        "X = df.drop(columns=['target', sensitive_feature])\n",
        "y = df['target']\n",
        "sensitive = df[sensitive_feature]\n",
        "\n",
        "# 🧪 Split the data\n",
        "X_train, X_test, y_train, y_test, sens_train, sens_test = train_test_split(\n",
        "    X, y, sensitive, test_size=0.3, stratify=sensitive\n",
        ")\n",
        "\n",
        "# 🔁 Train the model\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# 📊 Fairness evaluation\n",
        "metric_frame = MetricFrame(\n",
        "    metrics={\n",
        "        'TPR': true_positive_rate,\n",
        "        'FPR': false_positive_rate,\n",
        "        'FNR': false_negative_rate,\n",
        "        'Selection Rate': selection_rate\n",
        "    },\n",
        "    y_true=y_test,\n",
        "    y_pred=y_pred,\n",
        "    sensitive_features=sens_test\n",
        ")\n",
        "\n",
        "print(\"📈 Fairness Metrics by Gender:\\n\")\n",
        "print(metric_frame.by_group)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im2f9_Xb59J3",
        "outputId": "5a6ec8b7-b72e-44aa-cc47-35ca4a91cb42"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.12.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.16.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.17.0)\n",
            "Downloading fairlearn-0.12.0-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/240.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m235.5/240.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.12.0\n",
            "📈 Fairness Metrics by Gender:\n",
            "\n",
            "          TPR       FPR    FNR  Selection Rate\n",
            "Gender                                        \n",
            "female  0.125  0.035294  0.875        0.043011\n",
            "male    0.000  0.022989  1.000        0.018692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tAZ6c-h86ErP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}